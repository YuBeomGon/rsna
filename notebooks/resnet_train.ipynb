{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "professional-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# import random\n",
    "# import shutil\n",
    "# import time\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torch.nn.parallel\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# import torch.distributed as dist\n",
    "\n",
    "import torch.optim\n",
    "# import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "# import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "# import torchvision.models as models\n",
    "from resnet import *\n",
    "\n",
    "from main import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superior-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 8, \n",
    "                          \"epochs\": 50, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'workers':4,\n",
    "                         'output_dir' :'../trained_models/retinanet/'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bright-voltage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0089, -0.0306, -0.0410, -0.0098, -0.0068,  0.0341, -0.0089],\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0202, -0.0044, -0.0183, -0.0284, -0.0152, -0.0016,  0.0093],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "backbone_model= torchvision.models.resnet101(pretrained=True)\n",
    "model = resnet101(pretrained=False)\n",
    "print(model.conv1.weight[0,0,0])\n",
    "model.load_state_dict(backbone_model.state_dict(), strict=False)\n",
    "print(model.conv1.weight[0,0,0])\n",
    "\n",
    "# num_ftrs = model.fc1.in_features\n",
    "# print(num_ftrs)\n",
    "# model.fc1 = nn.Linear(num_ftrs, 2) # target label is 2\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "potential-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading code\n",
    "data_dir = '../ILSVRC/Data/CLS-LOC/'\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "centered-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "short-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifteen-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "train_sampler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finnish-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=64, shuffle=(train_sampler is None),\n",
    "    num_workers=8, pin_memory=True, sampler=train_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outdoor-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32, shuffle=False,\n",
    "    num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fossil-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-techno",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch_retina/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][    0/20019]\tTime  1.165 ( 1.165)\tData  0.746 ( 0.746)\tLoss 7.0750e+00 (7.0750e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.00 (  0.00)\n"
     ]
    }
   ],
   "source": [
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    adjust_learning_rate(optimizer, epoch, args)\n",
    "\n",
    "    # train for one epoch\n",
    "    epoch_loss = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion, args)  \n",
    "    \n",
    "    train_loss.append(epoch_loss)\n",
    "    val_acc.append(acc1)\n",
    "    print('************train_loss {} val_acc {}*************'.format(epoch_loss, acc1))\n",
    "    \n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "#     if not args.multiprocessing_distributed or (args.multiprocessing_distributed\n",
    "#             and args.rank % ngpus_per_node == 0):\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': args.arch,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best, args, filename='../trained_model/checkpoint.pt')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-village",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-budget",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_retina",
   "language": "python",
   "name": "pytorch_retina"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
